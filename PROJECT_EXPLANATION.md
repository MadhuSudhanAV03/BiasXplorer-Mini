# BiasXplorer-Mini: Complete Project Explanation

## ğŸ“‹ Table of Contents
1. [Project Overview](#project-overview)
2. [Project Structure](#project-structure)
3. [Technology Stack](#technology-stack)
4. [Backend Architecture](#backend-architecture)
5. [Frontend Architecture](#frontend-architecture)
6. [Complete Flow](#complete-flow)
7. [File-by-File Breakdown](#file-by-file-breakdown)
8. [Data Flow Diagram](#data-flow-diagram)

---

## ğŸ¯ Project Overview

**BiasXplorer-Mini** is a full-stack web application designed to detect and correct bias in datasets. It handles two types of bias:

1. **Categorical Bias**: Class imbalance in categorical columns (e.g., gender: 90% male, 10% female)
2. **Continuous Skewness**: Distribution skewness in numerical columns (e.g., right-skewed income data)

### Key Features:
- Upload CSV/Excel files
- Automatic data preprocessing (remove NaN, duplicates)
- Column type classification (categorical vs continuous)
- Bias detection with severity levels (Low/Moderate/Severe)
- Multiple correction methods (SMOTE, transformations, etc.)
- Interactive visualizations (before/after charts)
- PDF report generation
- Downloadable corrected datasets

---

## ğŸ“ Project Structure

```
BiasXplorer-Mini/
â”œâ”€â”€ backend/                      # Flask API server
â”‚   â”œâ”€â”€ app.py                    # Main Flask application entry point
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ .flaskenv                 # Flask environment variables
â”‚   â”‚
â”‚   â”œâ”€â”€ resources/                # API route handlers (Blueprints)
â”‚   â”‚   â”œâ”€â”€ upload_routes.py      # File upload & preview
â”‚   â”‚   â”œâ”€â”€ preprocess_routes.py  # Data cleaning
â”‚   â”‚   â”œâ”€â”€ select_routes.py      # Column selection
â”‚   â”‚   â”œâ”€â”€ bias_routes.py        # Bias detection & correction
â”‚   â”‚   â””â”€â”€ report_routes.py      # Visualization & reporting
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                 # Business logic layer
â”‚   â”‚   â”œâ”€â”€ file_service.py       # File read/write operations
â”‚   â”‚   â”œâ”€â”€ bias_detection_service.py      # Detect categorical bias
â”‚   â”‚   â”œâ”€â”€ bias_correction_service.py     # Fix categorical bias
â”‚   â”‚   â”œâ”€â”€ skewness_detection_service.py  # Detect continuous skewness
â”‚   â”‚   â”œâ”€â”€ skewness_correction_service.py # Fix continuous skewness
â”‚   â”‚   â””â”€â”€ visualization_service.py        # Generate charts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Helper utilities
â”‚   â”‚   â”œâ”€â”€ data_stats.py         # Statistical calculations
â”‚   â”‚   â”œâ”€â”€ validators/           # Input validation
â”‚   â”‚   â”‚   â”œâ”€â”€ file_validator.py  # Validate filenames
â”‚   â”‚   â”‚   â””â”€â”€ path_validator.py  # Validate file paths
â”‚   â”‚   â””â”€â”€ transformers/         # Data transformation logic
â”‚   â”‚       â”œâ”€â”€ categorical.py     # SMOTE, over/undersample
â”‚   â”‚       â””â”€â”€ continuous.py      # Log, sqrt, Box-Cox transforms
â”‚   â”‚
â”‚   â”œâ”€â”€ uploads/                  # Uploaded & processed files
â”‚   â””â”€â”€ corrected/                # Corrected datasets

â”œâ”€â”€ frontend/                     # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.jsx              # React entry point
â”‚   â”‚   â”œâ”€â”€ App.jsx               # Router configuration
â”‚   â”‚   â”œâ”€â”€ index.css             # Global styles (Tailwind)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/                # Main page components
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx          # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx     # 7-step workflow orchestrator
â”‚   â”‚   â”‚   â””â”€â”€ ReportPage.jsx    # Final report with charts & downloads
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/           # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.jsx               # File upload interface
â”‚   â”‚   â”‚   â”œâ”€â”€ DatasetPreview.jsx           # Show data table
â”‚   â”‚   â”‚   â”œâ”€â”€ Preprocess.jsx               # Cleaning interface
â”‚   â”‚   â”‚   â”œâ”€â”€ ColumnSelector.jsx           # Select target column
â”‚   â”‚   â”‚   â”œâ”€â”€ FeatureSelector.jsx          # Classify column types
â”‚   â”‚   â”‚   â”œâ”€â”€ BiasDetection.jsx            # Show bias results
â”‚   â”‚   â”‚   â”œâ”€â”€ UnifiedBiasFix.jsx           # Combined fix interface
â”‚   â”‚   â”‚   â”œâ”€â”€ BiasFixSandbox.jsx           # Categorical correction
â”‚   â”‚   â”‚   â”œâ”€â”€ SkewnessFixSandbox.jsx       # Continuous correction
â”‚   â”‚   â”‚   â”œâ”€â”€ Visualization.jsx            # Chart display
â”‚   â”‚   â”‚   â”œâ”€â”€ ReportGenerator.jsx          # PDF generation
â”‚   â”‚   â”‚   â”œâ”€â”€ CategoricalColumnsModal.jsx  # Column type modal
â”‚   â”‚   â”‚   â””â”€â”€ Spinner.jsx                  # Loading indicator
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ hooks/
â”‚   â”‚       â””â”€â”€ usePersistedState.js  # Local storage state management
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json              # Node dependencies
â”‚   â”œâ”€â”€ vite.config.js            # Vite configuration
â”‚   â””â”€â”€ index.html                # HTML template

â”œâ”€â”€ report/                       # LaTeX report files
â””â”€â”€ README.md                     # Project documentation
```

---

## ğŸ›  Technology Stack

### Backend:
- **Flask**: Python web framework
- **Flask-Smorest**: REST API with OpenAPI/Swagger docs
- **Flask-CORS**: Cross-origin resource sharing
- **pandas**: Data manipulation
- **scikit-learn**: Machine learning algorithms
- **imbalanced-learn**: SMOTE and sampling techniques
- **scipy**: Statistical functions and Box-Cox transformation
- **plotly**: Chart generation
- **reportlab**: PDF generation (legacy)

### Frontend:
- **React.js 19**: UI library
- **React Router**: Navigation
- **Vite**: Build tool and dev server
- **Tailwind CSS**: Styling framework
- **Axios**: HTTP client for API calls
- **Plotly.js**: Interactive charts
- **html2pdf.js**: PDF generation from HTML

### Data Formats:
- CSV and Excel (.xlsx, .xls) file support
- JSON for API communication

---

## ğŸ”§ Backend Architecture

### 1. **app.py** - Main Application Factory

```python
from flask import Flask
from flask_smorest import Api
from flask_cors import CORS

# Import route blueprints
from resources.upload_routes import blp as UploadBlueprint
from resources.preprocess_routes import blp as PreprocessBlueprint
from resources.bias_routes import blp as BiasBlueprint
from resources.select_routes import blp as SelectBlueprint
from resources.report_routes import blp as ReportBlueprint

def create_app():
    app = Flask(__name__)
    
    # Enable CORS for frontend (localhost:5173)
    CORS(app, resources={r"/*": {"origins": ["http://localhost:5173"]}})
    
    # Initialize API with Swagger docs
    api = Api(app)
    
    # Register all blueprints (route modules)
    api.register_blueprint(UploadBlueprint)
    api.register_blueprint(PreprocessBlueprint)
    api.register_blueprint(BiasBlueprint)
    api.register_blueprint(SelectBlueprint)
    api.register_blueprint(ReportBlueprint)
    
    return app

if __name__ == "__main__":
    app = create_app()
    app.run(debug=True, port=5000)
```

**What it does:**
- Creates Flask application instance
- Configures CORS to allow frontend requests
- Registers all API route blueprints
- Enables Swagger UI at `/swagger-ui` for API documentation
- Runs on port 5000

---

### 2. **resources/** - API Route Handlers (Blueprints)

Each blueprint handles specific API endpoints:

#### **upload_routes.py**

**Endpoints:**
- `POST /api/upload` - Upload CSV/Excel file
- `POST /api/preview` - Preview first 10 rows

**Flow:**
```
Client uploads file
  â†“
Validate filename (security check)
  â†“
Save to uploads/ directory
  â†“
Return file path: "uploads/filename.csv"
```

**Key Functions:**
```python
@blp.route("/upload")
class UploadFile(MethodView):
    def post(self):
        # 1. Check if 'file' exists in request
        # 2. Validate filename (no ../, remove special chars)
        # 3. Save to uploads/ directory
        # 4. Return relative path
```

---

#### **preprocess_routes.py**

**Endpoint:** `POST /api/preprocess`

**Input:**
```json
{
  "file_path": "uploads/dataset.csv"
}
```

**Processing Steps:**
1. Read CSV/Excel file into pandas DataFrame
2. Count missing values (NaN) per column
3. Drop rows with ANY NaN values
4. Drop duplicate rows
5. Save cleaned file as `uploads/cleaned_dataset.csv`

**Output:**
```json
{
  "message": "Preprocessing complete",
  "missing_values": {"age": 5, "income": 2},
  "rows_before": 1000,
  "rows_with_na_removed": 7,
  "duplicates_removed": 3,
  "rows_after": 990,
  "dataset_shape": [990, 10],
  "cleaned_file_path": "uploads/cleaned_dataset.csv"
}
```

---

#### **select_routes.py**

**Endpoint:** `POST /api/select`

**Purpose:** Create a subset of the dataset with only selected columns

**Input:**
```json
{
  "file_path": "uploads/cleaned_dataset.csv",
  "selected_columns": ["age", "gender", "income"]
}
```

**Processing:**
1. Read dataset
2. Extract only specified columns
3. Save as `uploads/selected_cleaned_dataset.csv`

**Output:**
```json
{
  "message": "Selection complete",
  "selected_file_path": "uploads/selected_cleaned_dataset.csv",
  "shape": [990, 3]
}
```

---

#### **bias_routes.py** - Core Bias Detection & Correction

**Main Endpoints:**

##### 1. `POST /api/bias/detect` - Detect Categorical Bias

**Input:**
```json
{
  "file_path": "uploads/selected_dataset.csv",
  "categorical": ["gender", "region"]
}
```

**Processing (BiasDetectionService):**
```python
For each categorical column:
  1. Calculate class distribution (value_counts)
  2. Compute imbalance ratio = min_class / max_class
  3. Assign severity:
     - ratio >= 0.5  â†’ "Low"
     - ratio >= 0.2  â†’ "Moderate"
     - ratio < 0.2   â†’ "Severe"
```

**Output:**
```json
{
  "gender": {
    "Male": 0.85,
    "Female": 0.15,
    "severity": "Severe"
  },
  "region": {
    "North": 0.40,
    "South": 0.35,
    "East": 0.25,
    "severity": "Moderate"
  }
}
```

---

##### 2. `POST /api/bias/fix` - Fix Categorical Bias

**Input:**
```json
{
  "file_path": "uploads/selected_dataset.csv",
  "target_column": "gender",
  "method": "smote",
  "threshold": 0.5,
  "categorical_columns": ["region", "job_type"]
}
```

**Methods Available:**
- **smote**: Synthetic Minority Over-sampling (creates synthetic samples)
- **oversample**: Random oversampling (duplicates minority samples)
- **undersample**: Random undersampling (removes majority samples)
- **reweight**: Assigns sample weights (doesn't change data)

**Processing Flow:**
```
1. Load dataset
2. Separate features (X) and target (y)
3. Apply SMOTE or SMOTE-NC (if categorical columns provided)
4. Generate synthetic samples
5. Combine X and y back into DataFrame
6. Save corrected file with timestamp
7. Generate before/after statistics
```

**Output:**
```json
{
  "message": "Bias correction completed",
  "method": "smote",
  "threshold": 0.5,
  "before": {
    "Male": {"count": 850, "percentage": 0.85},
    "Female": {"count": 150, "percentage": 0.15},
    "total": 1000
  },
  "after": {
    "Male": {"count": 850, "percentage": 0.50},
    "Female": {"count": 850, "percentage": 0.50},
    "total": 1700
  },
  "corrected_file_path": "corrected/corrected_dataset_gender_1699876543.csv"
}
```

---

##### 3. `POST /api/skew/detect` - Detect Continuous Skewness

**Input:**
```json
{
  "file_path": "uploads/selected_dataset.csv",
  "continuous": ["age", "income", "score"]
}
```

**Processing (SkewnessDetectionService):**
```python
For each continuous column:
  1. Calculate skewness coefficient using scipy.stats.skew()
  2. Classify:
     - skewness < -0.5  â†’ "Left skew"
     - skewness > 0.5   â†’ "Right skew"
     - otherwise        â†’ "Approximately normal"
```

**Output:**
```json
{
  "age": {
    "skewness": 0.15,
    "classification": "Approximately normal"
  },
  "income": {
    "skewness": 2.5,
    "classification": "Right skew"
  },
  "score": {
    "skewness": -0.8,
    "classification": "Left skew"
  }
}
```

---

##### 4. `POST /api/skew/fix` - Fix Continuous Skewness

**Input:**
```json
{
  "file_path": "uploads/selected_dataset.csv",
  "column": "income",
  "method": "log"
}
```

**Methods Available:**
- **log**: Log transformation (log(x + 1))
- **sqrt**: Square root transformation
- **boxcox**: Box-Cox transformation (optimizes lambda parameter)

**Processing (SkewnessCorrectionService):**
```python
if method == "log":
    transformed = np.log1p(data)  # log(x + 1)
elif method == "sqrt":
    transformed = np.sqrt(data)
elif method == "boxcox":
    transformed, lambda_param = boxcox(data)
```

**Output:**
```json
{
  "message": "Skewness correction applied",
  "column": "income",
  "method": "log",
  "original_skewness": 2.5,
  "new_skewness": 0.3,
  "corrected_file_path": "corrected/corrected_dataset_income_1699876789.csv"
}
```

---

#### **report_routes.py**

**Endpoint:** `POST /api/visualize`

**Purpose:** Generate before/after charts for bias corrections

**Input:**
```json
{
  "categorical_corrections": {
    "gender": {
      "corrected_file_path": "corrected/corrected_gender.csv"
    }
  },
  "continuous_corrections": {
    "income": {
      "corrected_file_path": "corrected/corrected_income.csv"
    }
  }
}
```

**Processing (VisualizationService):**
```python
For each correction:
  1. Read original file
  2. Read corrected file
  3. Generate Plotly charts:
     - Categorical: Bar charts (class distribution)
     - Continuous: Histograms (distribution curves)
  4. Return chart data as JSON
```

**Output:**
```json
{
  "categorical": {
    "gender": {
      "before_chart": {...plotly_data...},
      "after_chart": {...plotly_data...}
    }
  },
  "continuous": {
    "income": {
      "before_chart": {...plotly_data...},
      "after_chart": {...plotly_data...}
    }
  }
}
```

---

### 3. **services/** - Business Logic Layer

#### **file_service.py**

**Key Methods:**
```python
class FileService:
    @staticmethod
    def read_dataset(file_path):
        """Read CSV or Excel file into pandas DataFrame"""
        
    @staticmethod
    def save_dataset(df, file_path):
        """Save DataFrame as CSV"""
        
    @staticmethod
    def get_preview(df, rows=10):
        """Return first N rows as JSON"""
```

---

#### **bias_detection_service.py**

**Key Methods:**
```python
class BiasDetectionService:
    @staticmethod
    def detect_imbalance(df, categorical_columns):
        """Calculate class distribution and severity"""
        result = {}
        for col in categorical_columns:
            dist = df[col].value_counts(normalize=True)
            ratio = min(dist) / max(dist)
            severity = "Low" if ratio >= 0.5 else "Moderate" if ratio >= 0.2 else "Severe"
            result[col] = {**dist.to_dict(), "severity": severity}
        return result
```

---

#### **bias_correction_service.py**

**Key Methods:**
```python
from imblearn.over_sampling import SMOTE, SMOTENC
from imblearn.under_sampling import RandomUnderSampler

class BiasCorrectionService:
    @staticmethod
    def apply_correction(df, target_col, method, threshold, categorical_columns):
        X = df.drop(columns=[target_col])
        y = df[target_col]
        
        if method == "smote":
            if categorical_columns:
                # Use SMOTE-NC for mixed data
                cat_indices = [X.columns.get_loc(c) for c in categorical_columns]
                sampler = SMOTENC(categorical_features=cat_indices, sampling_strategy=threshold)
            else:
                sampler = SMOTE(sampling_strategy=threshold)
            X_resampled, y_resampled = sampler.fit_resample(X, y)
        
        elif method == "oversample":
            # Duplicate minority samples
            ...
        
        elif method == "undersample":
            # Remove majority samples
            ...
        
        # Combine back into DataFrame
        df_corrected = pd.concat([X_resampled, y_resampled], axis=1)
        return df_corrected, metadata
```

---

#### **skewness_correction_service.py**

**Key Methods:**
```python
from scipy.stats import boxcox
import numpy as np

class SkewnessCorrectionService:
    @staticmethod
    def apply_transformation(df, column, method):
        data = df[column]
        
        if method == "log":
            transformed = np.log1p(data)  # Handles zero values
        
        elif method == "sqrt":
            transformed = np.sqrt(data)
        
        elif method == "boxcox":
            transformed, lambda_param = boxcox(data)
        
        df[column] = transformed
        return df, new_skewness
```

---

#### **visualization_service.py**

**Key Methods:**
```python
import plotly.graph_objects as go

class VisualizationService:
    @staticmethod
    def create_categorical_chart(df, column):
        """Create bar chart for categorical data"""
        counts = df[column].value_counts()
        fig = go.Figure(data=[go.Bar(x=counts.index, y=counts.values)])
        return fig.to_dict()
    
    @staticmethod
    def create_continuous_chart(df, column):
        """Create histogram for continuous data"""
        fig = go.Figure(data=[go.Histogram(x=df[column])])
        return fig.to_dict()
```

---

### 4. **utils/** - Helper Utilities

#### **validators/file_validator.py**

**Purpose:** Security validation for uploaded filenames

```python
class FileValidator:
    ALLOWED_EXTENSIONS = {'csv', 'xlsx', 'xls'}
    
    @staticmethod
    def validate_filename(filename):
        # Remove path traversal attacks (../)
        # Check file extension
        # Sanitize special characters
        if ".." in filename:
            return None, "Invalid filename"
        ext = filename.rsplit('.', 1)[1].lower()
        if ext not in FileValidator.ALLOWED_EXTENSIONS:
            return None, "File type not allowed"
        return filename, None
```

---

#### **validators/path_validator.py**

**Purpose:** Prevent path traversal attacks

```python
class PathValidator:
    @staticmethod
    def validate_upload_path(file_path, base_dir, upload_dir):
        # Convert relative path to absolute
        # Check if path is within allowed directory
        abs_path = os.path.join(base_dir, file_path)
        if not abs_path.startswith(upload_dir):
            return None, "Invalid file path"
        if not os.path.exists(abs_path):
            return None, "File not found"
        return abs_path, None
```

---

#### **transformers/categorical.py**

**Purpose:** Implements SMOTE and sampling algorithms

```python
from imblearn.over_sampling import SMOTE, SMOTENC

class CategoricalTransformer:
    @staticmethod
    def apply_smote(X, y, categorical_indices=None):
        if categorical_indices:
            sampler = SMOTENC(categorical_features=categorical_indices)
        else:
            sampler = SMOTE()
        X_resampled, y_resampled = sampler.fit_resample(X, y)
        return X_resampled, y_resampled
```

---

#### **transformers/continuous.py**

**Purpose:** Implements skewness transformations

```python
from scipy.stats import boxcox
import numpy as np

class ContinuousTransformer:
    @staticmethod
    def apply_log(data):
        return np.log1p(data)
    
    @staticmethod
    def apply_sqrt(data):
        return np.sqrt(data)
    
    @staticmethod
    def apply_boxcox(data):
        transformed, lambda_param = boxcox(data)
        return transformed, lambda_param
```

---

## ğŸ¨ Frontend Architecture

### 1. **main.jsx** - React Entry Point

```jsx
import ReactDOM from 'react-dom/client'
import App from './App.jsx'
import './index.css'  // Tailwind CSS

ReactDOM.createRoot(document.getElementById('root')).render(
  <App />
)
```

**What it does:**
- Mounts React application to `<div id="root">` in index.html
- Imports global Tailwind CSS styles

---

### 2. **App.jsx** - Router Configuration

```jsx
import { createBrowserRouter, RouterProvider } from "react-router-dom";
import Home from "./pages/Home";
import Dashboard from "./pages/Dashboard";
import ReportPage from "./pages/ReportPage";

const router = createBrowserRouter([
  { path: "/", element: <Home /> },
  { path: "/dashboard", element: <Dashboard /> },
  { path: "/report", element: <ReportPage /> }
]);

export default function App() {
  return <RouterProvider router={router} />;
}
```

**Routes:**
- `/` â†’ Home page (file upload)
- `/dashboard` â†’ 7-step workflow
- `/report` â†’ Final report with charts

---

### 3. **pages/Home.jsx** - Landing Page

**Purpose:** Initial file upload

```jsx
import { useState } from "react";
import { useNavigate } from "react-router-dom";
import FileUpload from "../components/FileUpload";

export default function Home() {
  const [uploadedPath, setUploadedPath] = useState("");
  const navigate = useNavigate();

  const handleUploadSuccess = (filePath) => {
    setUploadedPath(filePath);
    navigate("/dashboard", { state: { filePath } });
  };

  return (
    <div>
      <h1>BiasXplorer-Mini</h1>
      <FileUpload onUploadSuccess={handleUploadSuccess} />
    </div>
  );
}
```

**Flow:**
1. User uploads file via FileUpload component
2. On success, navigate to /dashboard with file path

---

### 4. **pages/Dashboard.jsx** - Main Workflow Orchestrator

**Purpose:** Manages 7-step bias detection and correction workflow

**State Management:**
```jsx
const [currentStep, setCurrentStep] = useState(1);
const [filePath, setFilePath] = useState("");
const [columns, setColumns] = useState([]);
const [selectedColumns, setSelectedColumns] = useState([]);
const [categorical, setCategorical] = useState([]);
const [continuous, setContinuous] = useState([]);
const [biasResults, setBiasResults] = useState({});
const [skewnessResults, setSkewnessResults] = useState({});
const [correctedFilePath, setCorrectedFilePath] = useState("");
```

**7 Steps:**

#### **Step 1: Dataset Preview**
```jsx
<DatasetPreview 
  filePath={filePath}
  onColumnsLoaded={(cols) => setColumns(cols)}
  onNext={() => setCurrentStep(2)}
/>
```
- Shows first 10 rows of uploaded file
- Extracts column names

---

#### **Step 2: Data Preprocessing**
```jsx
<Preprocess
  filePath={filePath}
  onPreprocessComplete={(cleanedPath) => {
    setFilePath(cleanedPath);
    setCurrentStep(3);
  }}
/>
```
- Calls `POST /api/preprocess`
- Removes NaN and duplicates
- Updates file path to cleaned version

---

#### **Step 3: Target Column Selection**
```jsx
<ColumnSelector
  columns={columns}
  selectedColumns={selectedColumns}
  onSelectColumns={(selected) => {
    setSelectedColumns(selected);
    setCurrentStep(4);
  }}
/>
```
- User selects which columns to analyze
- Calls `POST /api/select` to create subset
- Updates file path to selected version

---

#### **Step 4: Column Type Classification**
```jsx
<FeatureSelector
  columns={selectedColumns}
  onClassify={(cat, cont) => {
    setCategorical(cat);
    setContinuous(cont);
    setCurrentStep(5);
  }}
/>
```
- User classifies columns as categorical or continuous
- Stores classifications for next steps

---

#### **Step 5: Bias Detection**
```jsx
<BiasDetection
  filePath={filePath}
  categorical={categorical}
  continuous={continuous}
  onDetectionComplete={(biasRes, skewRes) => {
    setBiasResults(biasRes);
    setSkewnessResults(skewRes);
    setCurrentStep(6);
  }}
/>
```
- Calls `POST /api/bias/detect` for categorical
- Calls `POST /api/skew/detect` for continuous
- Shows severity levels and distributions

---

#### **Step 6: Bias Fix**
```jsx
<UnifiedBiasFix
  filePath={filePath}
  categorical={categorical}
  continuous={continuous}
  biasResults={biasResults}
  skewnessResults={skewnessResults}
  onFixComplete={(correctedPath) => {
    setCorrectedFilePath(correctedPath);
    setCurrentStep(7);
  }}
/>
```
- User selects correction methods
- Applies fixes one column at a time
- Updates file path after each fix

---

#### **Step 7: Visualization**
```jsx
<Visualization
  corrections={allCorrections}
  onVisualizationComplete={(vizData) => {
    navigate("/report", { state: { vizData, corrections } });
  }}
/>
```
- Calls `POST /api/visualize`
- Generates before/after charts
- Navigates to report page

---

### 5. **pages/ReportPage.jsx** - Final Report

**Purpose:** Display comprehensive report with charts and download options

**Features:**
1. **Bias Summary**: Shows counts of Low/Moderate/Severe bias
2. **Correction Summary**: Lists all corrections applied
3. **Visualizations**: Interactive Plotly charts (before/after)
4. **Categorical Corrections Table**: Detailed table with method, threshold, before/after counts
5. **Continuous Corrections Table**: Skewness values and transformation methods
6. **PDF Download**: Generate downloadable report
7. **CSV Download**: Download corrected dataset

**Key Functions:**
```jsx
const downloadPDF = async () => {
  // Use html2pdf.js to convert HTML to PDF
  const element = document.getElementById('report-content');
  html2pdf().from(element).save('bias-report.pdf');
};

const downloadCorrectedCSV = async () => {
  // Download the final corrected CSV file
  const response = await axios.get(`/api/download/${correctedFilePath}`);
  // Trigger browser download
};
```

---

### 6. **Components** - Reusable UI Elements

#### **FileUpload.jsx**
```jsx
const handleFileChange = (e) => {
  const file = e.target.files[0];
  const formData = new FormData();
  formData.append('file', file);
  
  axios.post('/api/upload', formData)
    .then(response => {
      onUploadSuccess(response.data.file_path);
    });
};
```

---

#### **DatasetPreview.jsx**
```jsx
useEffect(() => {
  axios.post('/api/preview', { file_path: filePath })
    .then(response => {
      setPreviewData(response.data.rows);
      setColumns(response.data.columns);
    });
}, [filePath]);
```

---

#### **Preprocess.jsx**
```jsx
const handlePreprocess = () => {
  axios.post('/api/preprocess', { file_path: filePath })
    .then(response => {
      setStats(response.data);
      onPreprocessComplete(response.data.cleaned_file_path);
    });
};
```

---

#### **BiasDetection.jsx**
```jsx
const detectBias = () => {
  // Categorical bias
  axios.post('/api/bias/detect', { 
    file_path: filePath,
    categorical: categorical
  })
    .then(response => setBiasResults(response.data));
  
  // Continuous skewness
  axios.post('/api/skew/detect', {
    file_path: filePath,
    continuous: continuous
  })
    .then(response => setSkewnessResults(response.data));
};
```

---

#### **BiasFixSandbox.jsx** (Categorical)
```jsx
const applyFix = () => {
  axios.post('/api/bias/fix', {
    file_path: filePath,
    target_column: selectedColumn,
    method: selectedMethod,
    threshold: threshold,
    categorical_columns: otherCategorical
  })
    .then(response => {
      setBeforeAfter(response.data);
      onFixComplete(response.data.corrected_file_path);
    });
};
```

---

#### **SkewnessFixSandbox.jsx** (Continuous)
```jsx
const applyFix = () => {
  axios.post('/api/skew/fix', {
    file_path: filePath,
    column: selectedColumn,
    method: selectedMethod
  })
    .then(response => {
      setSkewnessBefore(response.data.original_skewness);
      setSkewnessAfter(response.data.new_skewness);
      onFixComplete(response.data.corrected_file_path);
    });
};
```

---

#### **Visualization.jsx**
```jsx
import Plot from 'react-plotly.js';

const Visualization = ({ chartData }) => {
  return (
    <Plot
      data={chartData.data}
      layout={chartData.layout}
      config={{ responsive: true }}
    />
  );
};
```

---

### 7. **hooks/usePersistedState.js**

**Purpose:** Save state to localStorage to persist across page refreshes

```jsx
export function usePersistedState(key, defaultValue) {
  const [state, setState] = useState(() => {
    const saved = localStorage.getItem(key);
    return saved ? JSON.parse(saved) : defaultValue;
  });

  useEffect(() => {
    localStorage.setItem(key, JSON.stringify(state));
  }, [key, state]);

  return [state, setState];
}
```

**Usage:**
```jsx
const [filePath, setFilePath] = usePersistedState("dashboard_filePath", "");
// State persists even after page refresh!
```

---

## ğŸ”„ Complete Data Flow

### **Scenario: User fixes gender bias using SMOTE**

#### **1. Upload File**
```
User (Browser)
  â†“ Selects file
FileUpload.jsx
  â†“ FormData with file
POST /api/upload
  â†“
upload_routes.py
  â†“ Validate & save
uploads/dataset.csv
  â†“ Return path
Home.jsx
  â†“ Navigate
Dashboard.jsx (Step 1)
```

---

#### **2. Preview Dataset**
```
Dashboard.jsx (Step 1)
  â†“
DatasetPreview.jsx
  â†“ POST /api/preview {"file_path": "uploads/dataset.csv"}
preprocess_routes.py
  â†“
FileService.read_dataset()
  â†“ pandas.read_csv()
DataFrame
  â†“ df.head(10)
JSON with rows and columns
  â†“
DatasetPreview.jsx
  â†“ Display table
User sees data
```

---

#### **3. Preprocess Data**
```
Dashboard.jsx (Step 2)
  â†“
Preprocess.jsx
  â†“ POST /api/preprocess {"file_path": "uploads/dataset.csv"}
preprocess_routes.py
  â†“
FileService.read_dataset()
  â†“
DataFrame.dropna() â†’ Remove NaN
  â†“
DataFrame.drop_duplicates() â†’ Remove duplicates
  â†“
FileService.save_dataset() â†’ uploads/cleaned_dataset.csv
  â†“ Return stats
Preprocess.jsx
  â†“ Show stats
Dashboard.jsx updates filePath to "uploads/cleaned_dataset.csv"
```

---

#### **4. Select Columns**
```
Dashboard.jsx (Step 3)
  â†“
ColumnSelector.jsx
  â†“ User selects: ["age", "gender", "income"]
  â†“ POST /api/select
select_routes.py
  â†“
DataFrame[selected_columns]
  â†“ Save subset
uploads/selected_cleaned_dataset.csv
  â†“
Dashboard.jsx updates filePath
```

---

#### **5. Classify Column Types**
```
Dashboard.jsx (Step 4)
  â†“
FeatureSelector.jsx
  â†“ User marks:
    categorical = ["gender"]
    continuous = ["age", "income"]
  â†“
Dashboard.jsx stores classifications
```

---

#### **6. Detect Bias**
```
Dashboard.jsx (Step 5)
  â†“
BiasDetection.jsx
  â†“ POST /api/bias/detect
    {
      "file_path": "uploads/selected_cleaned_dataset.csv",
      "categorical": ["gender"]
    }
  â†“
bias_routes.py â†’ BiasDetectionService
  â†“
For "gender" column:
  1. value_counts(normalize=True)
     â†’ {"Male": 0.85, "Female": 0.15}
  2. ratio = 0.15 / 0.85 = 0.176
  3. severity = "Severe" (< 0.2)
  â†“
Return: {
  "gender": {
    "Male": 0.85,
    "Female": 0.15,
    "severity": "Severe"
  }
}
  â†“
BiasDetection.jsx displays red badge "Severe"
  â†“
Dashboard.jsx stores biasResults
```

---

#### **7. Fix Gender Bias**
```
Dashboard.jsx (Step 6)
  â†“
UnifiedBiasFix.jsx â†’ BiasFixSandbox.jsx
  â†“ User selects:
    - Column: "gender"
    - Method: "smote"
    - Threshold: 0.5
  â†“ POST /api/bias/fix
    {
      "file_path": "uploads/selected_cleaned_dataset.csv",
      "target_column": "gender",
      "method": "smote",
      "threshold": 0.5,
      "categorical_columns": []
    }
  â†“
bias_routes.py â†’ BiasCorrectionService
  â†“
1. Load DataFrame (1000 rows)
2. X = df.drop(columns=["gender"])
   y = df["gender"]
   
3. Apply SMOTE:
   from imblearn.over_sampling import SMOTE
   sampler = SMOTE(sampling_strategy=0.5)
   X_resampled, y_resampled = sampler.fit_resample(X, y)
   
4. SMOTE creates synthetic "Female" samples:
   Before: Male=850, Female=150
   After:  Male=850, Female=425 (added 275 synthetic)
   
5. Combine back into DataFrame (1275 rows)

6. Save: corrected/corrected_selected_cleaned_dataset_gender_1699876543.csv

7. Calculate statistics:
   before = {"Male": 850, "Female": 150}
   after = {"Male": 850, "Female": 425}
  â†“
Return: {
  "message": "Bias correction completed",
  "method": "smote",
  "before": {...},
  "after": {...},
  "corrected_file_path": "corrected/..."
}
  â†“
BiasFixSandbox.jsx shows before/after table
  â†“
Dashboard.jsx updates correctedFilePath
```

---

#### **8. Generate Visualizations**
```
Dashboard.jsx (Step 7)
  â†“
Visualization.jsx
  â†“ POST /api/visualize
    {
      "categorical_corrections": {
        "gender": {
          "original_file_path": "uploads/selected_cleaned_dataset.csv",
          "corrected_file_path": "corrected/corrected_...csv"
        }
      }
    }
  â†“
report_routes.py â†’ VisualizationService
  â†“
1. Load original file
   gender_counts_before = {"Male": 850, "Female": 150}

2. Load corrected file
   gender_counts_after = {"Male": 850, "Female": 425}

3. Generate Plotly charts:
   
   before_chart = {
     "data": [{
       "type": "bar",
       "x": ["Male", "Female"],
       "y": [850, 150],
       "marker": {"color": "oklch(0.55 0.15 250)"}
     }],
     "layout": {
       "title": "Gender Distribution - Before",
       "xaxis": {"title": "Class"},
       "yaxis": {"title": "Count"}
     }
   }
   
   after_chart = {
     "data": [{
       "type": "bar",
       "x": ["Male", "Female"],
       "y": [850, 425],
       "marker": {"color": "oklch(0.65 0.15 150)"}
     }],
     "layout": {
       "title": "Gender Distribution - After",
       "xaxis": {"title": "Class"},
       "yaxis": {"title": "Count"}
     }
   }
  â†“
Return: {
  "categorical": {
    "gender": {
      "before_chart": {...},
      "after_chart": {...}
    }
  }
}
  â†“
Visualization.jsx renders Plotly charts
  â†“
User clicks "Go to Report"
  â†“
Navigate to /report with visualizations data
```

---

#### **9. View Report**
```
ReportPage.jsx
  â†“ Receives visualizations from navigation state
  â†“
Display Report:
  - Bias Summary
    â€¢ Columns fixed: 1 (gender)
    â€¢ Total columns selected: 3
    â€¢ Categorical:
      - Severe: 1 (gender)
  
  - Correction Summary
    â€¢ Categorical:
      - Total selected: 1
      - Needing fix: 1
      - Fixed: 1
  
  - Categorical Corrections Table
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Column â”‚ Method â”‚ Threshold â”‚ Before Total â”‚ After Total â”‚ Before Ratio â”‚ After Ratio â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ gender â”‚ smote  â”‚ 0.5       â”‚ 1000         â”‚ 1275        â”‚ 0.176        â”‚ 0.5         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  - Visualizations
    [Before Bar Chart: Male=850, Female=150]
    [After Bar Chart: Male=850, Female=425]
  
  - Download Buttons
    [Download PDF Report]
    [Download Corrected CSV]
```

---

#### **10. Download Corrected Dataset**
```
User clicks "Download CSV"
  â†“
ReportPage.jsx
  â†“ Create download link
const link = document.createElement('a');
link.href = `/api/download/corrected/corrected_...csv`;
link.download = 'corrected_dataset.csv';
link.click();
  â†“
Browser downloads file from backend
  â†“
User receives: corrected_dataset.csv (1275 rows, balanced gender)
```

---

## ğŸ“Š Key Algorithms Explained

### **1. SMOTE (Synthetic Minority Over-sampling Technique)**

**Purpose:** Generate synthetic samples for minority class

**Algorithm:**
```python
For each minority sample:
  1. Find K nearest neighbors (default K=5) from same class
  2. Randomly select one neighbor
  3. Create synthetic sample along line between original and neighbor:
     synthetic = original + Î» Ã— (neighbor - original)
     where Î» is random value between 0 and 1

Repeat until desired class balance achieved
```

**Example:**
```
Original data:
  Male: 850 samples
  Female: 150 samples

After SMOTE (target ratio 0.5):
  Male: 850 samples
  Female: 425 samples (150 original + 275 synthetic)
```

**Why it works:**
- Synthetic samples are similar to real data (interpolated)
- Increases minority class without exact duplication
- Helps ML models learn minority patterns better

---

### **2. SMOTE-NC (SMOTE for Numerical and Categorical)**

**Purpose:** SMOTE for datasets with mixed data types

**Algorithm:**
```python
For categorical columns:
  1. Use mode (most common value) of K neighbors
  2. Synthetic sample gets this mode value

For numerical columns:
  1. Use standard SMOTE interpolation
  2. synthetic = original + Î» Ã— (neighbor - original)
```

**Example:**
```
Original minority sample:
  age=25, gender=Female, region=North

K=5 neighbors:
  age=[24, 26, 23, 27, 25], gender=[F,F,F,F,F], region=[N,N,S,N,N]

Synthetic sample:
  age = 25 + 0.3 Ã— (24 - 25) = 24.7  â† Interpolated
  gender = Female                     â† Mode of neighbors
  region = North                      â† Mode of neighbors
```

---

### **3. Box-Cox Transformation**

**Purpose:** Find optimal transformation to make data more normal

**Algorithm:**
```python
For Î» (lambda) values from -5 to 5:
  if Î» = 0:
    transformed = log(x)
  else:
    transformed = (x^Î» - 1) / Î»
  
  Calculate log-likelihood of transformed data
  
Select Î» with highest log-likelihood
```

**Example:**
```
Original income data (right-skewed):
  [10000, 15000, 20000, 50000, 100000]
  skewness = 2.5

Optimal Î» = 0.2

Transformed:
  [(10000^0.2 - 1) / 0.2, ...]
  â‰ˆ [3.98, 4.43, 4.75, 6.46, 7.94]
  skewness = 0.3
```

---

## ğŸ” Security Features

### **1. Path Traversal Protection**
```python
# Prevents: ../../../etc/passwd
if ".." in file_path:
    return error

abs_path = os.path.abspath(file_path)
if not abs_path.startswith(UPLOAD_DIR):
    return error
```

---

### **2. File Type Validation**
```python
ALLOWED_EXTENSIONS = {'csv', 'xlsx', 'xls'}

ext = filename.rsplit('.', 1)[1].lower()
if ext not in ALLOWED_EXTENSIONS:
    return error
```

---

### **3. Filename Sanitization**
```python
import re

# Remove special characters
filename = re.sub(r'[^a-zA-Z0-9._-]', '', filename)
```

---

### **4. CORS Configuration**
```python
CORS(app, resources={
    r"/*": {
        "origins": ["http://localhost:5173"],  # Only allow frontend
        "methods": ["GET", "POST", "PUT", "DELETE"]
    }
})
```

---

## ğŸ¯ Error Handling

### **Backend Error Patterns**
```python
try:
    # Operation
    df = FileService.read_dataset(path)
except FileNotFoundError:
    return jsonify({"error": "File not found"}), 404
except ValueError as e:
    return jsonify({"error": f"Invalid data: {str(e)}"}), 400
except Exception as e:
    return jsonify({"error": str(e)}), 500
```

---

### **Frontend Error Patterns**
```jsx
axios.post('/api/endpoint', data)
  .then(response => {
    // Success
  })
  .catch(error => {
    if (error.response) {
      // Server returned error
      alert(error.response.data.error);
    } else {
      // Network error
      alert("Network error");
    }
  });
```

---

## ğŸ“ˆ Performance Optimizations

### **1. Persistent State (Frontend)**
- Uses localStorage to cache workflow state
- User can refresh page without losing progress
- Implemented via `usePersistedState` hook

### **2. Lazy Loading (Frontend)**
- React Router code-splitting
- Components load only when needed

### **3. Efficient Data Processing (Backend)**
- pandas vectorized operations (fast)
- Avoid loops where possible
- Use `.to_dict()` for JSON serialization

### **4. Visualization Optimization**
- Use plotly.js-dist-min (minified version)
- Reduces bundle size from 3.5MB â†’ 1.2MB
- Faster initial page load

---

## ğŸ§ª Testing Scenarios

### **Test Case 1: Gender Bias**
```
Input: gender column [Male: 850, Female: 150]
Method: SMOTE, threshold=0.5
Expected: [Male: 850, Female: 425]
```

### **Test Case 2: Multi-class Bias**
```
Input: region [North: 400, South: 300, East: 200, West: 100]
Method: SMOTE, threshold=0.8
Expected: Bring all classes closer to 400
```

### **Test Case 3: Right-skewed Income**
```
Input: income [10k, 15k, 20k, 50k, 100k, 200k]
Skewness: 2.5
Method: log transformation
Expected: Skewness â‰ˆ 0.3
```

---

## ğŸš€ Deployment Considerations

### **Backend Deployment:**
```bash
# Production server
gunicorn -w 4 -b 0.0.0.0:5000 app:app

# Environment variables
export FLASK_ENV=production
export UPLOAD_DIR=/var/uploads
```

### **Frontend Deployment:**
```bash
# Build for production
npm run build

# Deploy to static hosting (Netlify, Vercel, etc.)
# Build output: dist/
```

### **Docker Setup:**
```dockerfile
# Backend Dockerfile
FROM python:3.11
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "app:app"]

# Frontend Dockerfile
FROM node:18
WORKDIR /app
COPY package.json .
RUN npm install
COPY . .
RUN npm run build
CMD ["npm", "run", "preview"]
```

---

## ğŸ“š Key Dependencies Explained

### **Backend:**
- **Flask**: Web framework
- **pandas**: Data manipulation (like Excel in Python)
- **scikit-learn**: Machine learning library
- **imbalanced-learn**: SMOTE implementation
- **scipy**: Statistical functions (Box-Cox, skewness)
- **plotly**: Chart generation

### **Frontend:**
- **React**: UI library (component-based)
- **React Router**: Page navigation
- **Axios**: HTTP client (talks to backend)
- **Plotly.js**: Interactive charts
- **Tailwind CSS**: Utility-first styling
- **html2pdf.js**: Convert HTML to PDF

---

## ğŸ“ Learning Points

### **1. Full-Stack Architecture**
- Frontend (React) and Backend (Flask) separation
- RESTful API design
- JSON for data exchange

### **2. Data Science Pipeline**
- Upload â†’ Clean â†’ Analyze â†’ Correct â†’ Report
- Industry-standard workflow

### **3. Real-World Problem Solving**
- Class imbalance affects ML model fairness
- Skewed data affects statistical analysis
- Automated solutions save time

### **4. Modern Web Development**
- React hooks (useState, useEffect)
- Component reusability
- State management
- Responsive design (Tailwind)

### **5. Python Data Science Stack**
- pandas for data manipulation
- scikit-learn for ML
- scipy for statistics
- plotly for visualization

---

## ğŸ”— System Integration Map

```
User Browser
    â†“ HTTP
React App (localhost:5173)
    â†“ Axios (JSON)
Flask API (localhost:5000)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Services   â”‚  Validators  â”‚ Transformers  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ File        â”‚ Path         â”‚ SMOTE         â”‚
â”‚ Detection   â”‚ File         â”‚ Transforms    â”‚
â”‚ Correction  â”‚              â”‚               â”‚
â”‚ Viz         â”‚              â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
File System
    â”œâ”€â”€ uploads/
    â””â”€â”€ corrected/
```

---

This comprehensive explanation covers every aspect of the BiasXplorer-Mini project. Each file, function, and flow is documented with examples and code snippets. Use this as a complete reference for understanding, explaining, or extending the project!
