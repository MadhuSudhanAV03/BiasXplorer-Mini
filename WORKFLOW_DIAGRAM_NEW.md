# BiasXplorer-Mini - Complete Workflow Diagram (NEW)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BIASXPLORER-MINI WORKFLOW                            â”‚
â”‚                        (Updated: December 7, 2025)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 1: DATASET PREVIEW                                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  DatasetPreview.jsx                                            â•‘
â•‘ API:        POST /api/preview                                             â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ User uploads: dataset.csv                                             â•‘
â•‘                                                                            â•‘
â•‘ PROCESSING:                                                                â•‘
â•‘   â€¢ Validate file type (CSV/Excel)                                        â•‘
â•‘   â€¢ Read first 10 rows                                                    â•‘
â•‘   â€¢ Extract column names                                                  â•‘
â•‘                                                                            â•‘
â•‘ SERVER STORAGE:                                                            â•‘
â•‘   ğŸ“ backend/uploads/dataset.csv                                          â•‘
â•‘                                                                            â•‘
â•‘ BROWSER STORAGE (localStorage):                                           â•‘
â•‘   â€¢ dashboard_filePath: "uploads/dataset.csv"                             â•‘
â•‘   â€¢ dashboard_columns: ["col1", "col2", "col3", ...]                      â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT â†’ NEXT STEP:                                                        â•‘
â•‘   âœ… File path: "uploads/dataset.csv"                                     â•‘
â•‘   âœ… Column names: ["col1", "col2", "col3", ...]                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 2: TARGET COLUMN SELECTION â­ (MOVED UP)                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  FeatureSelector.jsx                                           â•‘
â•‘ API:        POST /api/features                                            â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ File: "uploads/dataset.csv" (original uploaded file)                 â•‘
â•‘   â€¢ All columns: ["col1", "col2", "col3", ...]                            â•‘
â•‘                                                                            â•‘
â•‘ USER ACTION:                                                               â•‘
â•‘   â€¢ User selects columns to analyze (checkboxes)                          â•‘
â•‘   â€¢ Example: ["age", "gender", "income"]                                  â•‘
â•‘                                                                            â•‘
â•‘ API REQUEST:                                                               â•‘
â•‘   POST /api/features                                                       â•‘
â•‘   {                                                                        â•‘
â•‘     "file_path": "uploads/dataset.csv",                                   â•‘
â•‘     "selected_features": ["age", "gender", "income"]                      â•‘
â•‘   }                                                                        â•‘
â•‘                                                                            â•‘
â•‘ BACKEND PROCESSING:                                                        â•‘
â•‘   1. Read uploads/dataset.csv                                             â•‘
â•‘   2. Filter DataFrame: df[["age", "gender", "income"]]                    â•‘
â•‘   3. Save filtered dataset                                                â•‘
â•‘                                                                            â•‘
â•‘ SERVER STORAGE:                                                            â•‘
â•‘   ğŸ“ backend/uploads/selected_dataset.csv                                 â•‘
â•‘   (Contains ONLY selected columns: age, gender, income)                   â•‘
â•‘                                                                            â•‘
â•‘ BROWSER STORAGE (localStorage):                                           â•‘
â•‘   â€¢ dashboard_selectedColumns: ["age", "gender", "income"]                â•‘
â•‘   â€¢ dashboard_selectedFilePath: "uploads/selected_dataset.csv"            â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT â†’ NEXT STEP:                                                        â•‘
â•‘   âœ… File path: "uploads/selected_dataset.csv"                            â•‘
â•‘   âœ… Selected columns: ["age", "gender", "income"]                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 3: COLUMN TYPE CLASSIFICATION â­ (MOVED UP)                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  ColumnSelector.jsx                                            â•‘
â•‘ API:        POST /api/column-types                                        â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ File: "uploads/selected_dataset.csv"                                  â•‘
â•‘   â€¢ Selected columns: ["age", "gender", "income"]                         â•‘
â•‘                                                                            â•‘
â•‘ USER ACTION:                                                               â•‘
â•‘   â€¢ Classify each column as Categorical or Continuous                     â•‘
â•‘   â€¢ Example:                                                               â•‘
â•‘     - Categorical: ["gender"]                                             â•‘
â•‘     - Continuous: ["age", "income"]                                       â•‘
â•‘                                                                            â•‘
â•‘ API REQUEST:                                                               â•‘
â•‘   POST /api/column-types                                                  â•‘
â•‘   {                                                                        â•‘
â•‘     "file_path": "uploads/selected_dataset.csv",                          â•‘
â•‘     "categorical": ["gender"],                                            â•‘
â•‘     "continuous": ["age", "income"]                                       â•‘
â•‘   }                                                                        â•‘
â•‘                                                                            â•‘
â•‘ BACKEND PROCESSING:                                                        â•‘
â•‘   1. Validate columns exist in selected_dataset.csv                       â•‘
â•‘   2. Store in Flask app.config (in-memory)                                â•‘
â•‘                                                                            â•‘
â•‘ SERVER STORAGE:                                                            â•‘
â•‘   ğŸ’¾ Flask Memory: app.config["COLUMN_TYPES_STORE"]                       â•‘
â•‘   {                                                                        â•‘
â•‘     "uploads/selected_dataset.csv": {                                     â•‘
â•‘       "categorical": ["gender"],                                          â•‘
â•‘       "continuous": ["age", "income"]                                     â•‘
â•‘     }                                                                      â•‘
â•‘   }                                                                        â•‘
â•‘   âš ï¸ Lost on server restart!                                              â•‘
â•‘                                                                            â•‘
â•‘ BROWSER STORAGE (localStorage):                                           â•‘
â•‘   â€¢ dashboard_categorical: ["gender"]                                     â•‘
â•‘   â€¢ dashboard_continuous: ["age", "income"]                               â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT â†’ NEXT STEP:                                                        â•‘
â•‘   âœ… File path: "uploads/selected_dataset.csv" (unchanged)                â•‘
â•‘   âœ… Column types stored                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 4: DATA PREPROCESSING â­ (MOVED DOWN, ENHANCED)                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  Preprocess.jsx                                                â•‘
â•‘ API:        POST /api/preprocess                                          â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ File: "uploads/selected_dataset.csv"                                  â•‘
â•‘   â€¢ Selected columns: ["age", "gender", "income"]                         â•‘
â•‘                                                                            â•‘
â•‘ API REQUEST: â­ NEW PARAMETER                                              â•‘
â•‘   POST /api/preprocess                                                    â•‘
â•‘   {                                                                        â•‘
â•‘     "file_path": "uploads/selected_dataset.csv",                          â•‘
â•‘     "selected_columns": ["age", "gender", "income"]  âœ¨ NEW!             â•‘
â•‘   }                                                                        â•‘
â•‘                                                                            â•‘
â•‘ BACKEND PROCESSING:                                                        â•‘
â•‘   1. Read uploads/selected_dataset.csv (all columns)                      â•‘
â•‘   2. Count missing values IN SELECTED COLUMNS ONLY:                       â•‘
â•‘      missing = df[["age", "gender", "income"]].isna().sum()              â•‘
â•‘   3. Drop rows with NaN IN SELECTED COLUMNS ONLY:                         â•‘
â•‘      df = df.dropna(subset=["age", "gender", "income"])                  â•‘
â•‘   4. Drop duplicates CONSIDERING SELECTED COLUMNS ONLY:                   â•‘
â•‘      df = df.drop_duplicates(subset=["age", "gender", "income"])         â•‘
â•‘   5. Save ENTIRE DataFrame (cleaned based on selected columns)            â•‘
â•‘                                                                            â•‘
â•‘ EXAMPLE:                                                                   â•‘
â•‘   Original: 1000 rows, 10 columns                                         â•‘
â•‘   Selected: 3 columns (age, gender, income)                               â•‘
â•‘   NaN in "age": 50 rows â†’ REMOVED                                         â•‘
â•‘   NaN in "other_column": NOT considered                                   â•‘
â•‘   Result: 950 rows, 10 columns (but cleaned for age/gender/income)       â•‘
â•‘                                                                            â•‘
â•‘ SERVER STORAGE:                                                            â•‘
â•‘   ğŸ“ backend/uploads/cleaned_selected_dataset.csv                         â•‘
â•‘   (All columns, but rows cleaned based on selected columns)               â•‘
â•‘                                                                            â•‘
â•‘ API RESPONSE: â­ NEW FIELD                                                 â•‘
â•‘   {                                                                        â•‘
â•‘     "message": "Preprocessing complete",                                  â•‘
â•‘     "selected_columns_cleaned": ["age", "gender", "income"],  âœ¨ NEW!    â•‘
â•‘     "missing_values": {"age": 50, "gender": 0, "income": 10},            â•‘
â•‘     "rows_before": 1000,                                                  â•‘
â•‘     "rows_with_na_removed": 50,                                           â•‘
â•‘     "duplicates_removed": 5,                                              â•‘
â•‘     "rows_after": 945,                                                    â•‘
â•‘     "dataset_shape": [945, 10],                                           â•‘
â•‘     "cleaned_file_path": "uploads/cleaned_selected_dataset.csv"           â•‘
â•‘   }                                                                        â•‘
â•‘                                                                            â•‘
â•‘ BROWSER STORAGE (localStorage):                                           â•‘
â•‘   â€¢ dashboard_cleanedFilePath: "uploads/cleaned_selected_dataset.csv"     â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT â†’ NEXT STEP:                                                        â•‘
â•‘   âœ… File path: "uploads/cleaned_selected_dataset.csv"                    â•‘
â•‘   âœ… Dataset is now clean and ready for analysis                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 5: BIAS DETECTION                                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  BiasDetection.jsx                                             â•‘
â•‘ API:        POST /api/bias/detect (categorical)                           â•‘
â•‘             POST /api/skewness/detect (continuous)                        â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ File: "uploads/cleaned_selected_dataset.csv"                          â•‘
â•‘   â€¢ Categorical columns: ["gender"]                                       â•‘
â•‘   â€¢ Continuous columns: ["age", "income"]                                 â•‘
â•‘                                                                            â•‘
â•‘ PROCESSING:                                                                â•‘
â•‘   â€¢ Detect class imbalance in categorical columns                         â•‘
â•‘   â€¢ Detect skewness in continuous columns                                 â•‘
â•‘                                                                            â•‘
â•‘ BROWSER STORAGE:                                                           â•‘
â•‘   â€¢ dashboard_biasResults: {...}                                          â•‘
â•‘   â€¢ dashboard_skewnessResults: {...}                                      â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT â†’ NEXT STEP:                                                        â•‘
â•‘   âœ… Bias detection results with severity levels                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 6: BIAS FIX                                                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  UnifiedBiasFix.jsx                                            â•‘
â•‘ API:        POST /api/bias/fix (categorical)                              â•‘
â•‘             POST /api/skewness/fix (continuous)                           â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ File: "uploads/cleaned_selected_dataset.csv"                          â•‘
â•‘   â€¢ Bias results from Step 5                                              â•‘
â•‘                                                                            â•‘
â•‘ PROCESSING:                                                                â•‘
â•‘   â€¢ Apply correction methods (SMOTE, reweight, transformations)           â•‘
â•‘                                                                            â•‘
â•‘ SERVER STORAGE:                                                            â•‘
â•‘   ğŸ“ backend/corrected/corrected_..._<timestamp>.csv                      â•‘
â•‘                                                                            â•‘
â•‘ BROWSER STORAGE:                                                           â•‘
â•‘   â€¢ dashboard_correctedFilePath: "corrected/..."                          â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT â†’ NEXT STEP:                                                        â•‘
â•‘   âœ… Corrected dataset                                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STEP 7: VISUALIZATION                                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Component:  Visualization.jsx                                             â•‘
â•‘ API:        POST /api/bias/visualize                                      â•‘
â•‘             POST /api/skewness/visualize                                  â•‘
â•‘                                                                            â•‘
â•‘ INPUT:                                                                     â•‘
â•‘   â€¢ Before: "uploads/cleaned_selected_dataset.csv"                        â•‘
â•‘   â€¢ After: "corrected/corrected_..._<timestamp>.csv"                      â•‘
â•‘                                                                            â•‘
â•‘ OUTPUT:                                                                    â•‘
â•‘   â€¢ Before/After charts (Plotly)                                          â•‘
â•‘   â€¢ PDF report generation                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FILE PROGRESSION SUMMARY                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Step 1: uploads/dataset.csv                   (Original upload)            â”‚
â”‚            â†“                                                                 â”‚
â”‚  Step 2: uploads/selected_dataset.csv          (Selected columns only)      â”‚
â”‚            â†“                                                                 â”‚
â”‚  Step 3: uploads/selected_dataset.csv          (No change, types stored)    â”‚
â”‚            â†“                                                                 â”‚
â”‚  Step 4: uploads/cleaned_selected_dataset.csv  (Cleaned selected columns)   â”‚
â”‚            â†“                                                                 â”‚
â”‚  Step 5: uploads/cleaned_selected_dataset.csv  (Detection)                  â”‚
â”‚            â†“                                                                 â”‚
â”‚  Step 6: corrected/corrected_..._<ts>.csv      (Fixed bias)                 â”‚
â”‚            â†“                                                                 â”‚
â”‚  Step 7: Visualizations + PDF Report                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         KEY IMPROVEMENTS (NEW WORKFLOW)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  âœ… Column selection happens BEFORE preprocessing                           â”‚
â”‚  âœ… Preprocessing operates ONLY on selected columns                         â”‚
â”‚  âœ… More efficient (doesn't clean unused columns)                           â”‚
â”‚  âœ… Better user control (pick what to analyze first)                        â”‚
â”‚  âœ… Smaller intermediate files (selected columns only)                      â”‚
â”‚  âœ… Type classification informs preprocessing                               â”‚
â”‚  âœ… Logical flow: Select â†’ Classify â†’ Clean â†’ Detect â†’ Fix                 â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
